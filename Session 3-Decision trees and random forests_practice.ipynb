{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection and Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Cross-validation: evaluating estimator performance\n",
    "\n",
    "http://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "#### (2) Or it could be used for tuning hyper-parameters.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/grid_search.html#grid-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating estimator performance.\n",
    "Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. To avoid it, it is common practice when performing supervised machine learning to hold out part of the available data as a test set (X_test, y_test), then to learn a model on the remaining (training) data and evaluate its accuracy on the test data.\n",
    "\n",
    "#### Tuning hyper-parameters\n",
    "If you have a model with important hyper-parameters (e.g., the amount of penalization for Lasso or Ridge regression), you can tune (find good values of) these hyperparameters by further splitting the training data into a training and validation set (still keeping the test data separate from these for a final, unbiased measure of performance).  To tune the hyper-parameters you can try a range of parameter values, learning from the (reduced) training set and evaluating performance on the validation set, and choose the hyper-parameters with best validation set performance.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_price</th>\n",
       "      <th>gross_sq_feet</th>\n",
       "      <th>mean</th>\n",
       "      <th>Adopt A Basket</th>\n",
       "      <th>Air Quality</th>\n",
       "      <th>Animal Abuse</th>\n",
       "      <th>Animal Facility   No Permit</th>\n",
       "      <th>Animal in a Park</th>\n",
       "      <th>APPLIANCE</th>\n",
       "      <th>Asbestos</th>\n",
       "      <th>...</th>\n",
       "      <th>Unsanitary Pigeon Condition</th>\n",
       "      <th>Urinating in Public</th>\n",
       "      <th>Vacant Lot</th>\n",
       "      <th>Vending</th>\n",
       "      <th>Violation of Park Rules</th>\n",
       "      <th>Water Conservation</th>\n",
       "      <th>Water Quality</th>\n",
       "      <th>Water System</th>\n",
       "      <th>Window Guard</th>\n",
       "      <th>X Ray Machine Equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000</td>\n",
       "      <td>1624</td>\n",
       "      <td>80098.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.049281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5200000</td>\n",
       "      <td>3840</td>\n",
       "      <td>149723.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>2120</td>\n",
       "      <td>84085.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.007354</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.069058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>775000</td>\n",
       "      <td>3423</td>\n",
       "      <td>46614.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.006756</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151000</td>\n",
       "      <td>2136</td>\n",
       "      <td>44634.0</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.037445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sale_price  gross_sq_feet      mean  Adopt A Basket  Air Quality  \\\n",
       "0      600000           1624   80098.0        0.000000     0.027721   \n",
       "1     5200000           3840  149723.0        0.000000     0.010675   \n",
       "2      100000           2120   84085.0        0.000000     0.002511   \n",
       "3      775000           3423   46614.0        0.000000     0.001476   \n",
       "4      151000           2136   44634.0        0.000049     0.001671   \n",
       "\n",
       "   Animal Abuse  Animal Facility   No Permit  Animal in a Park  APPLIANCE  \\\n",
       "0           0.0                     0.000000          0.000770   0.000257   \n",
       "1           0.0                     0.000000          0.000227   0.000227   \n",
       "2           0.0                     0.000000          0.001076   0.001973   \n",
       "3           0.0                     0.000000          0.000170   0.006756   \n",
       "4           0.0                     0.000049          0.000344   0.006143   \n",
       "\n",
       "   Asbestos           ...             Unsanitary Pigeon Condition  \\\n",
       "0  0.001027           ...                                0.000000   \n",
       "1  0.003861           ...                                0.000227   \n",
       "2  0.000359           ...                                0.000000   \n",
       "3  0.000738           ...                                0.000170   \n",
       "4  0.000688           ...                                0.000491   \n",
       "\n",
       "   Urinating in Public  Vacant Lot   Vending  Violation of Park Rules  \\\n",
       "0             0.000000    0.000000  0.001797                 0.001540   \n",
       "1             0.000227    0.000000  0.010675                 0.000454   \n",
       "2             0.000000    0.004484  0.000000                 0.000179   \n",
       "3             0.000170    0.000908  0.000568                 0.000170   \n",
       "4             0.000197    0.005897  0.000590                 0.000393   \n",
       "\n",
       "   Water Conservation  Water Quality  Water System  Window Guard  \\\n",
       "0            0.003850       0.002053      0.049281           0.0   \n",
       "1            0.001817       0.000227      0.050874           0.0   \n",
       "2            0.007354       0.001256      0.069058           0.0   \n",
       "3            0.000454       0.000341      0.012433           0.0   \n",
       "4            0.001622       0.000442      0.037445           0.0   \n",
       "\n",
       "   X Ray Machine Equipment  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "\n",
       "[5 rows x 162 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data: predicting housing price using 311 calls for service\n",
    "path = 'https://serv.cusp.nyu.edu/~cq299/ADS2016/Data/Bayesian/'\n",
    "data4=pd.read_csv(path + \"example4.csv\", low_memory=False)\n",
    "list_311=list(data4.loc[:,\"Adopt A Basket\":\"X Ray Machine Equipment\"].columns)\n",
    "data5=data4[[\"sale_price\",\"gross_sq_feet\",\"mean\"]+list_311]\n",
    "data5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2375, 161)\n",
      "(2375,)\n"
     ]
    }
   ],
   "source": [
    "X=np.matrix(data5.iloc[:,1:])\n",
    "y=np.asarray(data5.sale_price)\n",
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89192513812308927"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-sample R^2 value for ridge regression using the whole training dataset\n",
    "from sklearn import linear_model\n",
    "lm=linear_model.LinearRegression()\n",
    "lm.fit(X,y)\n",
    "1-((lm.predict(X)-y)**2).mean()/y.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/zhoubaoling/anaconda/envs/py27/lib/python27.zip',\n",
       " '/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7',\n",
       " '/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/plat-darwin',\n",
       " '/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/plat-mac',\n",
       " '/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/plat-mac/lib-scriptpackages',\n",
       " '/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/lib-tk',\n",
       " '/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/lib-old',\n",
       " '/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/lib-dynload',\n",
       " '/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages',\n",
       " '/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/IPython/extensions',\n",
       " '/Users/zhoubaoling/.ipython']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.14311343271\n"
     ]
    }
   ],
   "source": [
    "# How well do we do out of sample?  Let's split the data into 60% training, 40% test, and average performance over 10 random splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "OS=[]\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = i)    \n",
    "    lm=linear_model.LinearRegression()\n",
    "    lm.fit(X_train,y_train)\n",
    "    OS.append(1-((lm.predict(X_test)-y_test)**2).mean()/y_test.var()) # or equivalently: OS.append(lm.score(X_test,y_test))\n",
    "print np.mean(OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536580673591\n"
     ]
    }
   ],
   "source": [
    "# Does ridge regression do better out of sample?  Let's try with an arbitrary choice of penalization parameter alpha = 1.\n",
    "OS=[]\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = i)    \n",
    "    lm=linear_model.Ridge(alpha=1)\n",
    "    lm.fit(X_train,y_train)\n",
    "    OS.append(1-((lm.predict(X_test)-y_test)**2).mean()/y_test.var()) # or equivalently: OS.append(lm.score(X_test,y_test))\n",
    "print np.mean(OS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "Exhaustive Grid Search. The grid search provided by GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the param_grid parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tune the hyper-parameters for ridge regression and calculate the OS R-squared using the new tuned alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.041026581058271942}\n",
      "{'alpha': 0.041026581058271942}\n",
      "{'alpha': 0.0001320088400831418}\n",
      "{'alpha': 0.79340966657974921}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ee694e8ed95f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mOS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/ridge.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \"\"\"\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/ridge.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_n_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                 return_intercept=False)\n\u001b[0m\u001b[1;32m    507\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/ridge.pyc\u001b[0m in \u001b[0;36mridge_regression\u001b[0;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, random_state, return_n_iter, return_intercept)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_solve_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;31m# use SVD solver if matrix is singular\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/ridge.pyc\u001b[0m in \u001b[0;36m_solve_cholesky\u001b[0;34m(X, y, alpha)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mn_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mXy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhoubaoling/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid ={'alpha':np.logspace(-4, 0, 200)}\n",
    "\n",
    "OS=[]\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = i)\n",
    "    rid=linear_model.Ridge()\n",
    "    gr=GridSearchCV(rid,param_grid=param_grid)\n",
    "    rs=gr.fit(X_train,y_train)\n",
    "    print rs.best_params_\n",
    "    OS.append(1-((rs.predict(X_test)-y_test)**2).mean()/y_test.var())\n",
    "print np.mean(OS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Decision Tree. \n",
    "\n",
    "Stop-and-Frisk Data set: https://en.wikipedia.org/wiki/Stop-and-frisk_in_New_York_City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download the data set here or on NYU-Classes.\n",
    "https://serv.cusp.nyu.edu/classes/ML_2016_Spring/ML_2017/\n",
    "\n",
    "file: \"session_3_stop.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"session_3_stop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove records with any missing values\n",
    "data=data.dropna()\n",
    "\n",
    "# Let's take \"found.weapon\" as the target variable. \n",
    "y=data.loc[:,\"found.weapon\"]\n",
    "\n",
    "# Get the feature space.  We are using only features from before the stop, getting rid of features from during/after the stop like \"arrested\".\n",
    "X=data.loc[:,\"suspect.race\":\"time.period\"]\n",
    "X=pd.get_dummies(X)\n",
    "\n",
    "# Split data into 70% train, 30% test\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3, random_state=999)\n",
    "print X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part one: IS and OS Accuracy of prediction. \n",
    "\n",
    "DecisionTreeClassifier:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# learn model\n",
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "# in sample accuracy\n",
    "print 'In sample accuracy:',dt.score(X_train,y_train)\n",
    "\n",
    "# out of sample accuracy\n",
    "print 'Out of sample accuracy:',dt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice #1: Get the average OS accuracy over 10 train/test splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does that mean our model is super good? However... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What would our accuracy be if we predicted 0 (no weapon found) for everyone?\n",
    "print 1.*len(y_test[y_test==0])/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use area under the receiver operating characteristic curve (\"ROC AUC\") instead of accuracy.\n",
    "\n",
    "ROC, Area under the curve:\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics\n",
    "\n",
    "https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "\n",
    "Youtube:\n",
    "https://www.youtube.com/watch?v=hnRBl9-BzjQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "AUC_OS=[]\n",
    "for i in range(10):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    dt=DecisionTreeClassifier()\n",
    "    dt.fit(X_train,y_train)\n",
    "    # predict_proba predicts the probability of each class rather than just the most likely class\n",
    "    pred=dt.predict_proba(X_test)[:,1] # predicted probability of y = 1\n",
    "    AUC_OS.append(roc_auc_score(np.array(y_test),pred))\n",
    "print \"OS AUC\",np.mean(AUC_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How well would we expect to do just by chance?\n",
    "chance_OS=[]\n",
    "for i in range(10):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    pred=np.random.random(len(X_test))\n",
    "    chance_OS.append(roc_auc_score(np.array(y_test.apply(int)),pred))\n",
    "print np.mean(chance_OS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control the complexity of the Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's just use a single train/test split for this part:\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3,random_state=999)\n",
    "AUC_OS=[]\n",
    "for i in range(2,500,25):\n",
    "    dt=DecisionTreeClassifier(max_leaf_nodes=i)\n",
    "    dt.fit(X_train,y_train)\n",
    "    AUC_OS.append(roc_auc_score(np.array(y_test),dt.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(2,500,25),AUC_OS)\n",
    "plt.xlabel(\"Max leaf nodes\")\n",
    "plt.ylabel(\"OS_AUC\")\n",
    "plt.title(\"AUC vs Simplicity (max leaf nodes)\")\n",
    "plt.xlim(2,500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As an aside: predict_proba vs. predict\n",
    "tm=pd.concat((pd.DataFrame(dt.predict_proba(X_test)),pd.DataFrame(dt.predict(X_test))),axis=1)\n",
    "tm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This time we'll use max_depth to control the complexity of the tree, still using the same train/test split as above,\n",
    "# and optimize the parameter value using GridSearchCV.\n",
    "param_grid = {'max_depth':range(1,11)}\n",
    "dt=DecisionTreeClassifier()\n",
    "gr=GridSearchCV(dt,param_grid=param_grid,scoring='roc_auc')\n",
    "rs=gr.fit(X_train,y_train)\n",
    "print rs.best_params_\n",
    "print roc_auc_score(np.array(y_test),rs.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "Decision trees can be used for feature selection by calculating the Gini importance of each feature (higher = more important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=8)\n",
    "dt.fit(X_train, y_train)\n",
    "Feature_importance=pd.DataFrame([list(X_train.columns),list(dt.feature_importances_)]).T\n",
    "Feature_importance.columns=[\"variables\",\"importance\"]\n",
    "\n",
    "# list the top 5 most important features in order\n",
    "Feature_importance.sort_values(by=\"importance\",ascending=False).iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's generate our new training and testing model using the top three features.\n",
    "X_train_simple=X_train.loc[:,[\"stopped.bc.object\",\"location.housing_transit\",\"precinct\"]]\n",
    "X_test_simple=X_test.loc[:,[\"stopped.bc.object\",\"location.housing_transit\",\"precinct\"]]\n",
    "\n",
    "# Now let's see the performance of this simple model.\n",
    "dt = DecisionTreeClassifier(max_depth=8)\n",
    "dt.fit(X_train_simple, y_train)\n",
    "print \"The AUC score for this simple model with 3 features is\",roc_auc_score(y_test,dt.predict_proba(X_test_simple)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Tree we built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=2) # just to keep it simple for visualization\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "# display the output using www.webgraphviz.com, or if you have GraphViz installed on\n",
    "# your computer, you can use that\n",
    "print tree.export_graphviz(dt,out_file=None,\n",
    "                         feature_names=X_train.columns.values,  \n",
    "                         class_names=['no weapon found','weapon found'],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True,impurity=False).replace(\"<br/>\",\", \").replace(\"&le;\",\"<=\").replace(\"=<\",\"=\\\"\").replace(\">,\",\"\\\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to install GraphViz on your own machine:\n",
    "\n",
    "conda install graphviz\n",
    "\n",
    "pip install pydot\n",
    "\n",
    "pip install pydotplus\n",
    "\n",
    "For people who experienced this error: \"GraphViz's executables not found\"\n",
    "\n",
    "http://stackoverflow.com/questions/18438997/why-is-pydot-unable-to-find-graphvizs-executables-in-windows-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will only work if GraphViz is installed on your machine\n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "thestring = tree.export_graphviz(dt, out_file=None,  \n",
    "                         feature_names=X_train.columns.values, \n",
    "                         class_names=['no weapon found','weapon found'],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True,impurity=False)\n",
    "graph = pydotplus.graph_from_dot_data(thestring)  \n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same training data as above\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=30, n_jobs=-1,max_leaf_nodes=10)\n",
    "rf.fit(X_train, y_train)\n",
    "pred=rf.predict_proba(X_test)[:,1]\n",
    "print roc_auc_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice #2. Let's fix max_leaf_nodes=10, build forests with between 1 and 50 trees, and plot the AUC as a function of number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice #3.  Use GridSearchCV to optimize the hyperparameter, num_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the result (time permitting)\n",
    "\n",
    "For this part, let's select two categorical features, and make two corresponding plots\n",
    "comparing the average model prediction and empirical outcome for\n",
    "each value of that feature. \n",
    "\n",
    "For example, if a chosen feature is\n",
    "â€˜precinctâ€™, the plot should have a point for each precinct, where the\n",
    "x-value is the average model prediction for all stops in that precinct,\n",
    "and the y-value is the average value of your target variable for all\n",
    "stops in that precinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, n_jobs=4,max_leaf_nodes=30)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Let's pick two features, age and precinct, and save them with the result\n",
    "result=X_test.loc[:,['suspect.age','precinct']]\n",
    "result=pd.concat((y_test,result),axis=1)\n",
    "result['pred_prob']=rf.predict_proba(X_test)[:,1]\n",
    "result.index=range(len(result))\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa=result.groupby(\"precinct\").apply(lambda x: x.loc[:,[\"found.weapon\",\"pred_prob\"]].mean()).reset_index()\n",
    "aa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For precinct:\n",
    "plt.figure(figsize=(8,7.5))\n",
    "plt.scatter(list(aa.loc[:,\"pred_prob\"]),list(aa.loc[:,\"found.weapon\"]),c=\"r\")\n",
    "plt.title('Predicted weapon probability vs Real weapon probability by \"Precinct\"')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.xlim(0,0.5)\n",
    "plt.ylim(-0.01,0.5)\n",
    "plt.plot(list(aa.loc[:,\"found.weapon\"]),list(aa.loc[:,\"found.weapon\"]),'-b')\n",
    "\n",
    "#Let's label the precincts for which our model does not work well.\n",
    "for label, x, y in zip(list(aa.precinct), list(aa.loc[:,\"pred_prob\"]), list(aa.loc[:,\"found.weapon\"])):\n",
    "    if x-y>0.05:\n",
    "        \n",
    "        plt.annotate(\n",
    "            label, \n",
    "            xy = (x, y), xytext = (30, -30),\n",
    "            textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "            bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
    "            arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "    if x-y<-0.05:\n",
    "        plt.annotate(\n",
    "            label, \n",
    "            xy = (x, y), xytext = (-20, 20),\n",
    "            textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "            bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
    "            arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice #4\n",
    "\n",
    "Repeat this process and plot the result for \"suspect.age\" or for any feature you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
