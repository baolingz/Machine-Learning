{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named numpy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa44af558781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named numpy"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "\n",
    "Quickstart tutorial: https://docs.scipy.org/doc/numpy-dev/user/quickstart.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPyâ€™s main object is the homogeneous multidimensional array. It is a table of elements (usually numbers), all of the same type, indexed by a tuple of positive integers. In NumPy dimensions are called axes. The number of axes is rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a 2 (row) x 3 (column) array from a list of lists. Type can be specified or inferred.\n",
    "a=np.asarray([[1,2.5,3],[4,5,6]],dtype='float32')\n",
    "print a\n",
    "print\n",
    "print a.ndim\n",
    "print a.shape\n",
    "print\n",
    "\n",
    "# a's transpose is a 3 x 2 array. The value of a is not changed by this.\n",
    "aT = a.transpose()\n",
    "print aT\n",
    "print\n",
    "print aT.ndim\n",
    "print aT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of inferred type.  Here it assumes that these are integers... \n",
    "np.asarray([1,2]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ... unless you specify otherwise\n",
    "np.asarray([1,2],dtype=\"complex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exponential and logarithm (base e)\n",
    "print np.exp(1)\n",
    "print np.log(np.exp(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# built-in constants\n",
    "np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate an m x n array of random numbers, uniform on [0,1]\n",
    "np.random.rand(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standard trigonmetric operations\n",
    "np.sin(np.pi/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a uniformly spaced 1-D array (start,end,number of elements)\n",
    "np.linspace(0,2,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same idea, but take base to that power\n",
    "np.logspace(0,2,9,base=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# array of ones (input is a tuple of dimensions)\n",
    "np.ones((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# element-wise operations\n",
    "\n",
    "# add or multiply two matrices elementwise; returns ValueError if sizes do not match\n",
    "print np.ones((2,3))+np.ones((2,3))\n",
    "print\n",
    "print np.ones((2,3))*np.ones((2,3))\n",
    "print\n",
    "\n",
    "# casts the constant into an appropriately sized matrix\n",
    "print np.ones((2,3))+1\n",
    "print\n",
    "\n",
    "print np.ones((2,3))*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comparison operation is also performed element-wise; can compare to constant\n",
    "np.random.rand(5,5)>0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# again, sin is performed element-wise\n",
    "np.sin(np.random.rand(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So is division.  Vector is cast into matrix with appropriate number of rows  \n",
    "print np.asarray([0.1,0.2])\n",
    "print\n",
    "print np.ones((2,2))/np.asarray([0.1,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The new shape should be compatible with the original shape. \n",
    "# If an integer, then the result will be a 1-D array of that length. \n",
    "# One shape dimension can be -1. In this case, the value is inferred from the length of the array and remaining dimension\n",
    "print np.asarray([0.1,0.2]).reshape(-1,1)\n",
    "print\n",
    "print np.ones((2,2))/np.asarray([0.1,0.2]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = np.ones((2,2))/np.asarray([0.1,0.2]).reshape(-1,1)\n",
    "# min of each column\n",
    "print q.min(axis=0)\n",
    "print\n",
    "# min of each row\n",
    "print q.min(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp=np.ones((3,3))*2\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp.cumprod(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape into 1-D vector\n",
    "tmp.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn a 4 x 4 into a 2 x 2 x 2 x 2\n",
    "np.random.rand(4,4).reshape((2,2,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selection of elements from array\n",
    "tmp= np.random.rand(4,4)\n",
    "print tmp\n",
    "print\n",
    "print tmp.reshape(-1)[np.asarray([2,3,4,5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slice\n",
    "tmp[1:4,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pick out all elements satisfying condition as 1-D array\n",
    "tmp[tmp>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pick out rows where first element is >0.5\n",
    "tmp[tmp[:,0]>0.5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign values to a subset of array elements.  Note that this happens in place (i.e., the value of tmp is changed)\n",
    "tmp.reshape(-1)[[1,2,3,4]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Algebra\n",
    "a = np.array([[1.0, 2.0], [3.0, 4.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# element-wise\n",
    "a*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# element-wise\n",
    "a/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard matrix multiplication.  Not element-wise!\n",
    "np.dot(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print a\n",
    "np.trace(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas \n",
    "\n",
    "10 Minutes to pandas: http://pandas.pydata.org/pandas-docs/stable/10min.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Object Creation:\n",
    "\n",
    "# series\n",
    "s = pd.Series([1,3,5,np.nan,6,8])\n",
    "\n",
    "# dataframe\n",
    "dates = pd.date_range('20130101', periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({ 'A' : 1.,\n",
    "   ....:                      'B' : pd.Timestamp('20130102'),\n",
    "   ....:                      'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n",
    "   ....:                      'D' : np.array([3] * 4,dtype='int32'),\n",
    "   ....:                      'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n",
    "   ....:                      'F' : 'foo' })\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Viewing Data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sorting\n",
    "print df\n",
    "print\n",
    "\n",
    "# these operations do not change the value of df\n",
    "\n",
    "# sort rows by index\n",
    "print df.sort_index(axis=0, ascending=False) \n",
    "print\n",
    "# sort columns by column header\n",
    "print df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print df\n",
    "print\n",
    "# sort rows using values in a particular column\n",
    "print df.sort_values(by='B') # axis defaults to 0\n",
    "print\n",
    "# sort columns using values corresponding to a particular row index\n",
    "print df.sort_values(axis=1,by='2013-01-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Descriptive statistics of each column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selection\n",
    "\n",
    "# select a particular column (with row index) \n",
    "df['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select rows by slicing\n",
    "print df[1:3]\n",
    "print\n",
    "# equivalent but more flexible; select rows by integer positions\n",
    "print df.iloc[1:3,:]\n",
    "print\n",
    "# subsets of rows and columns, can slice or list\n",
    "print df.iloc[1:3,[1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select rows or columns by value\n",
    "df.loc[dates[0]] # equivalent to df.loc['2013-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can select row and column values\n",
    "df.loc[:,['A','C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc['20130102':'20130104',['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.iloc[1:4,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boolean Indexing\n",
    "\n",
    "# select all rows where a condition is met\n",
    "df[df.A > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filling in missing values\n",
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\n",
    "df1.loc[dates[1]:dates[2],'E'] = 1\n",
    "df1.loc[[dates[0],dates[3]],'E'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping rows with any missing values\n",
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\n",
    "df1.loc[dates[1]:dates[2],'E'] = 1\n",
    "df1.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in all missing values with a given value\n",
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\n",
    "df1.loc[dates[1]:dates[2],'E'] = 1\n",
    "df1.fillna(value=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# element-wise: is each value missing?\n",
    "print df1\n",
    "print\n",
    "pd.isnull(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply an operation to each column (e.g., sum across all rows for that column)\n",
    "print df\n",
    "print\n",
    "df.apply(sum,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply an operation to each row (e.g., sum across all columns for that row)\n",
    "df.apply(sum,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply an operation element-wise\n",
    "df.applymap(lambda x: x*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concat, Join, Append.\n",
    "\n",
    "# concatenate rows together\n",
    "df = pd.DataFrame(np.random.randn(10, 4))\n",
    "pieces = [df[:2], df[5:7], df[8:]]\n",
    "print pd.concat(pieces)\n",
    "print\n",
    "\n",
    "# concatenate columns together\n",
    "pieces = [df.iloc[:,0:2], df.iloc[:,3]]\n",
    "print pd.concat(pieces,axis=1)\n",
    "print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame({'key': ['B', 'A'], 'xval': [2, 1]})\n",
    "y = pd.DataFrame({'key': ['A', 'B','C'], 'yval': [4, 5,6]})\n",
    "print x\n",
    "print\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print y.merge(x,left_on=\"key\",right_on=\"key\",how=\"left\")\n",
    "print\n",
    "print x.merge(y,left_on=\"key\",right_on=\"key\",how=\"left\")\n",
    "print\n",
    "print x.merge(y,left_on=\"key\",right_on=\"key\",how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append\n",
    "print y.append(x, ignore_index=True)\n",
    "print \n",
    "print pd.concat([y,x],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grouping\n",
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar','foo', 'bar', 'foo', 'foo'],'B' : ['one', 'one', 'two', 'three','two', 'two', 'one', 'three'],\n",
    "'C' : np.random.randn(8),'D' : np.random.randn(8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(\"A\").apply(lambda x: x.loc[:,\"D\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp=df.groupby(['A','B']).sum()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stack and unstack\n",
    "print tmp\n",
    "print\n",
    "stacked=tmp.stack(level=-1) # -1, i.e., the last column, is the default level\n",
    "print stacked\n",
    "print\n",
    "unstacked = stacked.unstack(level=-1) # -1, i.e., the last column, is the default level\n",
    "print unstacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn\n",
    "\n",
    "1.Preprocessing.\n",
    "\n",
    "2.Supervised Learning.\n",
    "\n",
    "3.Model selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check your version and make sure >0.18\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. Preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale,  Normalization, Binarization, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[ 1., -1.,  2.],\n",
    "               [ 2.,  0.,  0.],\n",
    "             [ 0.,  1., -1.]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make each column have mean = 0 and std dev = 1\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Equivalently, we could use:\n",
    "(X-X.mean(axis=0))/X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize \n",
    "\n",
    "Normalization is the process of scaling individual samples to have unit norm. This process can be useful if you plan to use a quadratic form such as the dot-product or any other kernel to quantify the similarity of any pair of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print preprocessing.normalize(X,axis=0)\n",
    "print\n",
    "# equivalently, we could use:\n",
    "print X/np.sqrt((X*X).sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn has a ton of methods implemented, many of which we will see later in the course!\n",
    "\n",
    "### Supervised Learning \n",
    "\n",
    "(Regression/Classification)\n",
    "\n",
    "Linear Models (Ordinary Least Squares, Logistic Regression, Lasso and Ridge...)\n",
    "\n",
    "Kernel regression\n",
    "\n",
    "SVM\n",
    "\n",
    "Gaussian Processes\n",
    "\n",
    "Decision Trees and Random Forests (next class)\n",
    "\n",
    "Naive Bayes\n",
    "\n",
    "Supervised Neural Network models (incl. Deep Learning)\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "Clustering.\n",
    "\n",
    "Dimension Reduction.\n",
    "\n",
    "Representation in Neural Networks such as RBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Spectral)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "# we create an instance of logistic regression classifier and fit the data.\n",
    "logreg.fit(X, Y)\n",
    "\n",
    "# now the color represents the predicted class\n",
    "plt.scatter(X[:, 0], X[:, 1], c=logreg.predict(X), cmap=plt.cm.Spectral)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips: How to use packages from sklearn.\n",
    "\n",
    "Step one: What is the problem we want to solve and what is the model we want to fit. \n",
    "\n",
    "Step two: What are the hyper-parameters related to model structure.\n",
    "\n",
    "Step three: What are the inputs dataframe and what are the parameters we want to tune.\n",
    "\n",
    "Step four: What are hyper-parameters for training process. (learning rate, iteration max...)\n",
    "\n",
    "step five: What are the outputs and tuned parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Penalized Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data and problem.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "X = np.random.random((10,10))\n",
    "y = 5*(X[:,1]-0.5)+3*(X[:,5]-0.5)+np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas? Dimension reduction? Feature selection? Penalized model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso and Ridge \n",
    "\n",
    "Ridge:\n",
    "\n",
    "$\\underset{w}{min\\,} {{|| X w - y||_2}^2 + \\alpha {||w||_2}^2}$\n",
    "\n",
    "Lasso:\n",
    "\n",
    "$\\underset{w}{min\\,} { \\frac{1}{2n_{samples}} ||X w - y||_2 ^ 2 + \\alpha ||w||_1}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data set: X, y \n",
    "\n",
    "#### model: \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge\n",
    "\n",
    "#### Hyper-parameters to set\n",
    "(1) model related: alpha, fit_intercept\n",
    "\n",
    "(2) training related: normalize, copy_X, max_iter, tol, solver, random_state\n",
    "\n",
    "#### Parameters to tune (output)\n",
    "\n",
    "intercept_, coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the Ridge model using the given X and y.\n",
    "clf = linear_model.Ridge(fit_intercept=True,alpha=0.1)\n",
    "clf.fit(X,y)\n",
    "\n",
    "# let's look at the tuned parameter values.  As expected, we can see larger values on columns 1 and 5.\n",
    "print clf.coef_\n",
    "print clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict y given X\n",
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the in-sample R^2 value\n",
    "1-((clf.predict(X)-y)**2).mean()/y.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# or equivalently:\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will consider a range of alpha values and visualize the tuned weights (parameters) for each alpha\n",
    "n_alphas = 200\n",
    "alphas = np.logspace(-6, 1, n_alphas)\n",
    "\n",
    "coefs = []\n",
    "R_2=[]\n",
    "for a in alphas:\n",
    "    clf = linear_model.Ridge(fit_intercept=True,alpha=a)\n",
    "    clf.fit(X,y)\n",
    "    coefs.append(clf.coef_)\n",
    "    R_2.append(1-((clf.predict(X)-y)**2).mean()/y.var())\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse x-axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, R_2)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('R_2')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Same thing but try using Lasso instead of Ridge regression.\n",
    "# Lasso has the nice feature that many irrelevant attributes have weights reduced to 0 \n",
    "# (i.e., it gives a sparse model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection and Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Cross-validation: evaluating estimator performance\n",
    "\n",
    "http://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "#### (2) Or it could be used for tuning hyper-parameters.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/grid_search.html#grid-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating estimator performance.\n",
    "Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. To avoid it, it is common practice when performing supervised machine learning to hold out part of the available data as a test set (X_test, y_test), then to learn a model on the remaining (training) data and evaluate its accuracy on the test data.\n",
    "\n",
    "#### Tuning hyper-parameters\n",
    "If you have a model with important hyper-parameters (e.g., the amount of penalization for Lasso or Ridge regression), you can tune (find good values of) these hyperparameters by further splitting the training data into a training and validation set (still keeping the test data separate from these for a final, unbiased measure of performance).  To tune the hyper-parameters you can try a range of parameter values, learning from the (reduced) training set and evaluating performance on the validation set, and choose the hyper-parameters with best validation set performance.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing price prediction using 311 data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'https://serv.cusp.nyu.edu/~cq299/ADS2016/Data/Bayesian/'\n",
    "data4=pd.read_csv(path + \"example4.csv\", low_memory=False)\n",
    "list_311=list(data4.loc[:,\"Adopt A Basket\":\"X Ray Machine Equipment\"].columns)\n",
    "data5=data4[[\"sale_price\",\"gross_sq_feet\",\"mean\"]+list_311]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=np.matrix(data5.iloc[:,1:])\n",
    "y=np.asarray(data5.sale_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In-sample R^2 value for linear regression using the whole training dataset\n",
    "lm=linear_model.LinearRegression()\n",
    "lm.fit(X,y)\n",
    "1-((lm.predict(X)-y)**2).mean()/y.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How well do we do out of sample?  Let's split the data into 60% training, 40% test, and average performance over 10 random splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "OS=[]\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = i)    \n",
    "    lm=linear_model.LinearRegression()\n",
    "    lm.fit(X_train,y_train)\n",
    "    OS.append(1-((lm.predict(X_test)-y_test)**2).mean()/y_test.var())\n",
    "print np.mean(OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Or we could use score...\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "OS=[]\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = i)    \n",
    "    lm=linear_model.LinearRegression()\n",
    "    lm.fit(X_train,y_train)\n",
    "    OS.append(lm.score(X_test,y_test))\n",
    "print np.mean(OS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's repeat this analysis of out-of-sample performance for the Ridge model with alpha=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "Exhaustive Grid Search. The grid search provided by GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the param_grid parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tune the hyper-parameters for ridge regression and calculate the OS R-squared using the new tuned alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid ={'alpha':np.logspace(-4, 0, 200)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OS=[]\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = i)\n",
    "    rid=linear_model.Ridge()\n",
    "    gr=GridSearchCV(rid,param_grid=param_grid)\n",
    "    rs=gr.fit(X_train,y_train)\n",
    "    print rs.best_params_\n",
    "    OS.append(1-((rs.predict(X_test)-y_test)**2).mean()/y_test.var())\n",
    "print np.mean(OS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it for Lasso as well, reducing the resolution of the grid to speed up the run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid ={'alpha':np.logspace(-4, 0, 20)}\n",
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
